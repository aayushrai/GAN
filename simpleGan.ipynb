{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,LeakyReLU,Dropout,Flatten,Conv2DTranspose,Conv2DTranspose,Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3),strides=(2,2),padding=\"same\",input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=.2))\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(Conv2D(64,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=.2))\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    (X,_),(_,_) = load_data()\n",
    "    X = np.expand_dims(X,axis=-1)\n",
    "    X = X.astype(\"float32\")\n",
    "    X = X / 255.0\n",
    "    return X\n",
    "    \n",
    "def generate_real_samples(dataset,batch_size):\n",
    "    ix = np.random.randint(0,len(dataset),batch_size)\n",
    "    x = dataset[ix]\n",
    "    y = np.ones((batch_size,1))\n",
    "    return x,y\n",
    "\n",
    "def generate_fake_samples(batch_size):\n",
    "    x = np.random.rand(28*28*batch_size)\n",
    "    x = x.reshape((batch_size,28,28,1))\n",
    "    y = np.zeros((batch_size,1))\n",
    "    return x,y\n",
    "\n",
    "def train_discriminator(model,dataset,iteration,steps):\n",
    "    half_batch = steps//2\n",
    "    for i in range(iteration):\n",
    "        x_real,y_real = generate_real_samples(dataset,steps)\n",
    "        _,real_accuracy  = model.train_on_batch(x_real,y_real)\n",
    "        \n",
    "        x_fake,y_fake = generate_fake_samples(steps)\n",
    "        _,fake_accuracy = model.train_on_batch(x_fake,y_fake)\n",
    "        print('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_accuracy*100, fake_accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    # upsample to 14x14\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 28x28\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim,batch_size):\n",
    "    latent_points = np.random.randn(batch_size*latent_dim)\n",
    "    latent_points = latent_points.reshape((batch_size,latent_dim))\n",
    "    return latent_points\n",
    "\n",
    "def generate_fake_images_and_labels(g_model,latent_dim,batch_size):\n",
    "    x_input = generate_latent_points(latent_dim,batch_size)\n",
    "    x = g_model.predict(x_input)\n",
    "    y = np.zeros((batch_size,1))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GanModel(g_model,d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan_model, latent_dim, n_epochs=100, n_batch=256):\n",
    "    for i in range(n_epochs):\n",
    "        x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "        gan_model.train_on_batch(x_gan, y_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save a plot of generated images (reversed grayscale)\n",
    "def save_plot(examples, epoch, n=10):\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    " \n",
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    # prepare real samples\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_images_and_labels(g_model, latent_dim, n_samples)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performancetra\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    # save plot\n",
    "    save_plot(x_fake, epoch)\n",
    "    # save the generator model tile file\n",
    "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
    "    g_model.save(filename)\n",
    "\n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(bat_per_epo):\n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            # generate 'fake' examples\n",
    "            #generate fake image with generator\n",
    "            X_fake, y_fake = generate_fake_images_and_labels(g_model, latent_dim, half_batch)\n",
    "            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            # summarize loss on this batch\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "        # evaluate the model performance, sometimes\n",
    "        if (i+1) % 10 == 0:\n",
    "            summarize_performance(i, g_model, d_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 1/234, d=0.689, g=0.743\n",
      ">1, 2/234, d=0.685, g=0.759\n",
      ">1, 3/234, d=0.673, g=0.780\n",
      ">1, 4/234, d=0.670, g=0.794\n",
      ">1, 5/234, d=0.660, g=0.810\n",
      ">1, 6/234, d=0.653, g=0.829\n",
      ">1, 7/234, d=0.651, g=0.837\n",
      ">1, 8/234, d=0.648, g=0.844\n",
      ">1, 9/234, d=0.646, g=0.845\n",
      ">1, 10/234, d=0.650, g=0.834\n",
      ">1, 11/234, d=0.649, g=0.815\n",
      ">1, 12/234, d=0.656, g=0.790\n",
      ">1, 13/234, d=0.655, g=0.766\n",
      ">1, 14/234, d=0.664, g=0.747\n",
      ">1, 15/234, d=0.657, g=0.732\n",
      ">1, 16/234, d=0.659, g=0.723\n",
      ">1, 17/234, d=0.659, g=0.714\n",
      ">1, 18/234, d=0.652, g=0.709\n",
      ">1, 19/234, d=0.648, g=0.705\n",
      ">1, 20/234, d=0.638, g=0.702\n",
      ">1, 21/234, d=0.634, g=0.700\n",
      ">1, 22/234, d=0.621, g=0.700\n",
      ">1, 23/234, d=0.615, g=0.699\n",
      ">1, 24/234, d=0.606, g=0.699\n",
      ">1, 25/234, d=0.597, g=0.699\n",
      ">1, 26/234, d=0.589, g=0.699\n",
      ">1, 27/234, d=0.580, g=0.699\n",
      ">1, 28/234, d=0.576, g=0.700\n",
      ">1, 29/234, d=0.560, g=0.701\n",
      ">1, 30/234, d=0.552, g=0.702\n",
      ">1, 31/234, d=0.539, g=0.703\n",
      ">1, 32/234, d=0.527, g=0.704\n",
      ">1, 33/234, d=0.514, g=0.705\n",
      ">1, 34/234, d=0.500, g=0.706\n",
      ">1, 35/234, d=0.497, g=0.707\n",
      ">1, 36/234, d=0.483, g=0.708\n",
      ">1, 37/234, d=0.480, g=0.710\n",
      ">1, 38/234, d=0.463, g=0.711\n",
      ">1, 39/234, d=0.458, g=0.712\n",
      ">1, 40/234, d=0.450, g=0.714\n",
      ">1, 41/234, d=0.442, g=0.715\n",
      ">1, 42/234, d=0.436, g=0.717\n",
      ">1, 43/234, d=0.427, g=0.719\n",
      ">1, 44/234, d=0.422, g=0.721\n",
      ">1, 45/234, d=0.408, g=0.724\n",
      ">1, 46/234, d=0.404, g=0.727\n",
      ">1, 47/234, d=0.397, g=0.730\n",
      ">1, 48/234, d=0.393, g=0.733\n",
      ">1, 49/234, d=0.387, g=0.737\n",
      ">1, 50/234, d=0.383, g=0.741\n",
      ">1, 51/234, d=0.376, g=0.745\n",
      ">1, 52/234, d=0.375, g=0.749\n",
      ">1, 53/234, d=0.369, g=0.756\n",
      ">1, 54/234, d=0.357, g=0.761\n",
      ">1, 55/234, d=0.357, g=0.768\n",
      ">1, 56/234, d=0.352, g=0.775\n",
      ">1, 57/234, d=0.346, g=0.782\n",
      ">1, 58/234, d=0.340, g=0.790\n",
      ">1, 59/234, d=0.334, g=0.801\n",
      ">1, 60/234, d=0.329, g=0.811\n",
      ">1, 61/234, d=0.327, g=0.824\n",
      ">1, 62/234, d=0.317, g=0.840\n",
      ">1, 63/234, d=0.314, g=0.850\n",
      ">1, 64/234, d=0.308, g=0.868\n",
      ">1, 65/234, d=0.297, g=0.885\n",
      ">1, 66/234, d=0.291, g=0.905\n",
      ">1, 67/234, d=0.287, g=0.924\n",
      ">1, 68/234, d=0.274, g=0.947\n",
      ">1, 69/234, d=0.265, g=0.974\n",
      ">1, 70/234, d=0.266, g=1.001\n",
      ">1, 71/234, d=0.250, g=1.030\n",
      ">1, 72/234, d=0.246, g=1.061\n",
      ">1, 73/234, d=0.235, g=1.095\n",
      ">1, 74/234, d=0.228, g=1.133\n",
      ">1, 75/234, d=0.211, g=1.170\n",
      ">1, 76/234, d=0.203, g=1.218\n",
      ">1, 77/234, d=0.196, g=1.258\n",
      ">1, 78/234, d=0.184, g=1.305\n",
      ">1, 79/234, d=0.179, g=1.362\n",
      ">1, 80/234, d=0.168, g=1.407\n",
      ">1, 81/234, d=0.153, g=1.465\n",
      ">1, 82/234, d=0.154, g=1.523\n",
      ">1, 83/234, d=0.140, g=1.579\n",
      ">1, 84/234, d=0.136, g=1.637\n",
      ">1, 85/234, d=0.132, g=1.692\n",
      ">1, 86/234, d=0.117, g=1.749\n",
      ">1, 87/234, d=0.113, g=1.813\n",
      ">1, 88/234, d=0.106, g=1.874\n",
      ">1, 89/234, d=0.104, g=1.931\n",
      ">1, 90/234, d=0.100, g=1.983\n",
      ">1, 91/234, d=0.090, g=2.043\n",
      ">1, 92/234, d=0.088, g=2.091\n",
      ">1, 93/234, d=0.091, g=2.118\n",
      ">1, 94/234, d=0.094, g=2.002\n",
      ">1, 95/234, d=0.471, g=0.769\n",
      ">1, 96/234, d=2.806, g=0.019\n",
      ">1, 97/234, d=3.219, g=0.013\n",
      ">1, 98/234, d=2.583, g=0.044\n",
      ">1, 99/234, d=1.839, g=0.164\n",
      ">1, 100/234, d=1.198, g=0.460\n",
      ">1, 101/234, d=0.783, g=0.964\n",
      ">1, 102/234, d=0.535, g=1.493\n",
      ">1, 103/234, d=0.456, g=1.938\n",
      ">1, 104/234, d=0.440, g=2.144\n",
      ">1, 105/234, d=0.381, g=2.248\n",
      ">1, 106/234, d=0.369, g=2.233\n",
      ">1, 107/234, d=0.314, g=2.216\n",
      ">1, 108/234, d=0.322, g=2.320\n",
      ">1, 109/234, d=0.292, g=2.222\n",
      ">1, 110/234, d=0.275, g=2.215\n",
      ">1, 111/234, d=0.257, g=2.209\n",
      ">1, 112/234, d=0.260, g=2.134\n",
      ">1, 113/234, d=0.271, g=2.007\n",
      ">1, 114/234, d=0.266, g=1.906\n",
      ">1, 115/234, d=0.269, g=1.741\n",
      ">1, 116/234, d=0.288, g=1.592\n",
      ">1, 117/234, d=0.278, g=1.542\n",
      ">1, 118/234, d=0.269, g=1.465\n",
      ">1, 119/234, d=0.280, g=1.392\n",
      ">1, 120/234, d=0.299, g=1.326\n",
      ">1, 121/234, d=0.337, g=1.260\n",
      ">1, 122/234, d=0.323, g=1.194\n",
      ">1, 123/234, d=0.360, g=1.205\n",
      ">1, 124/234, d=0.367, g=1.132\n",
      ">1, 125/234, d=0.391, g=1.160\n",
      ">1, 126/234, d=0.365, g=1.120\n",
      ">1, 127/234, d=0.405, g=1.103\n",
      ">1, 128/234, d=0.394, g=1.117\n",
      ">1, 129/234, d=0.390, g=1.092\n",
      ">1, 130/234, d=0.395, g=1.132\n",
      ">1, 131/234, d=0.380, g=1.153\n",
      ">1, 132/234, d=0.377, g=1.196\n",
      ">1, 133/234, d=0.371, g=1.215\n",
      ">1, 134/234, d=0.383, g=1.261\n",
      ">1, 135/234, d=0.346, g=1.325\n",
      ">1, 136/234, d=0.353, g=1.321\n",
      ">1, 137/234, d=0.349, g=1.357\n",
      ">1, 138/234, d=0.330, g=1.386\n",
      ">1, 139/234, d=0.342, g=1.412\n",
      ">1, 140/234, d=0.318, g=1.478\n",
      ">1, 141/234, d=0.301, g=1.500\n",
      ">1, 142/234, d=0.281, g=1.504\n",
      ">1, 143/234, d=0.282, g=1.574\n",
      ">1, 144/234, d=0.281, g=1.580\n",
      ">1, 145/234, d=0.258, g=1.614\n",
      ">1, 146/234, d=0.253, g=1.603\n",
      ">1, 147/234, d=0.231, g=1.590\n",
      ">1, 148/234, d=0.269, g=1.482\n",
      ">1, 149/234, d=0.280, g=1.379\n",
      ">1, 150/234, d=0.269, g=1.375\n",
      ">1, 151/234, d=0.272, g=1.370\n",
      ">1, 152/234, d=0.249, g=1.409\n",
      ">1, 153/234, d=0.259, g=1.458\n",
      ">1, 154/234, d=0.227, g=1.537\n",
      ">1, 155/234, d=0.236, g=1.585\n",
      ">1, 156/234, d=0.215, g=1.616\n",
      ">1, 157/234, d=0.222, g=1.619\n",
      ">1, 158/234, d=0.196, g=1.647\n",
      ">1, 159/234, d=0.209, g=1.650\n",
      ">1, 160/234, d=0.214, g=1.665\n",
      ">1, 161/234, d=0.183, g=1.675\n",
      ">1, 162/234, d=0.193, g=1.709\n",
      ">1, 163/234, d=0.196, g=1.709\n",
      ">1, 164/234, d=0.188, g=1.733\n",
      ">1, 165/234, d=0.177, g=1.760\n",
      ">1, 166/234, d=0.181, g=1.761\n",
      ">1, 167/234, d=0.171, g=1.794\n",
      ">1, 168/234, d=0.156, g=1.802\n",
      ">1, 169/234, d=0.151, g=1.827\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "epochs = 11\n",
    "batch = 256\n",
    "# create the discriminator\n",
    "d_model = discriminator(input_shape=(28,28,1))\n",
    "# create the generator\n",
    "g_model = generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = GanModel(g_model, d_model)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim,epochs,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
